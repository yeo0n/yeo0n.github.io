---
layout: single
title: 챗GPT 프롬프트 통한 민감 정보 유출 막기 위해 등장한 프라이빗GPT (05-05 8주차)
date: 2023-05-05 16:16:59 +0900
categories: 
    - News
#tag: News
typora-root-url: ../
toc: true
toc_sticky: true
toc_label: 목차
author_profile: true
comment: true
sidebar:
    nav: "docs"
---
  

## 챗GPT 프롬프트 통한 민감 정보 유출 막기 위해 등장한 프라이빗GPT (05-05 8주차)

<br>

**챗GPT를 통해 깜짝 놀랄 만한 답변을 듣기 위해 사람들은 더욱 과감한 자세로 각종 정보를 입력하고 있다. 그러면서 평소 같았으면 조심스럽게 데이터를 다뤘을 것이 분명한 이들조차 아무 데이터를 마구 타이핑한다.**

이 도구의 이름은 프라이빗GPT(PrivateGPT)로, 오픈AI(OpenAI)의 챗GPT를 기반으로 하고 있으며, 50가지가 넘는 유형의 개인 식별 정보를 자동으로 찾아내 실시간으로 삭제한다고 한다. 여기서 ‘실시간’이란 사용자가 챗GPT에 요청문을 입력하는 타이밍을 얘기한다.  
  
**프라이버시 침해 가능성과 챗GPT**  
사용자가 데이터를 챗GPT 창에 입력할 때, 그 데이터는 챗GPT의 기반이 되는 대형 언어 모델(LLM)의 데이터셋에 포함된다. 이 데이터는 차세대 챗GPT 혹은 다른 인공지능 알고리즘을 훈련시키는 데 활용된다. 그러므로 사용자가 입력하는 데이터는 삭제되지 않으며, 이론적으로는 미래 어느 시점에 추출하는 것도 가능하다. 그러니 훈련용 데이터 혹은 사용자가 입력하는 데이터에 대한 안전 장치 마련이 시급하다고 볼 수 있다.  
  
글 : 타라 실즈(Tara Seals), IT 칼럼니스트  
\[국제부 문정후 기자([globoan@boannews.com](mailto:globoan@boannews.com))\]

출처: [https://www.boannews.com/media/view.asp?idx=117814&skind=D](https://www.boannews.com/media/view.asp?idx=117814&skind=D) 

 [챗GPT 프롬프트 통한 민감 정보 유출 막기 위해 등장한 프라이빗GPT

직원들이 챗GPT를 업무에 활용한답시고 각종 민감 정보를 마구 입력하고 있다는 지적이 기업들 사이에서 나오고 있다. 그런 가운데 한 데이터 프라이버시 전문 기업이 이러한 위험으로부터 기업

www.boannews.com](https://www.boannews.com/media/view.asp?idx=117814&skind=D)

* * *

느낀점: 요즘에 챗GPT를 쓰면서 개발이나 다양한 업무에 사용하지만 챗GPT에 입력한 데이터들이 유출될 수도 있기 때문에 조심해야할 것 같다. 많은 기업에서 챗GPT에 민감한 정보를 입력하지 않도록 규정하고 있는데 삼성에서 있었던 데이터 유출 사건을 계기로 기업에서 규정하고 있는 것 같은데 개인적인 생각은 프라이빗GPT가 나온다고 해서 아직 여러 기업들이 프라이빗GPT를 믿고 사용할 것 같진 않고 가격 또한 최대 10배로 나온다고 하니 기업들이 챗GPT 사용 방식에 민감한 데이터 노출에 대한 교육과 여러 방법을 통해서 챗GPT를 안전하게 사용하는게 더 좋은 방법이지 않나 개인적으로 생각한다.